---
title: "topic3"
author: "MORE"
date: "2025-09-01"
output: html_document
---

Q1)
```{r}
library(ISLR2)
set.seed(1)
data(Auto)
#View(Auto)
#a)
n=length(Auto$mpg)
train=sample(392,196)
#estimate of test error(test MSE)
lm.fit=lm(mpg~horsepower,data=Auto,subset = train)             
attach(Auto)
mean((mpg-predict(lm.fit,Auto))[-train]^2)
lm.fit2=lm(mpg~poly(horsepower,2),data=Auto,subset = train)
mean((mpg-predict(lm.fit2,Auto))[-train]^2)
lm.fit3=lm(mpg~poly(horsepower,3),data=Auto,subset = train)
mean((mpg-predict(lm.fit3,Auto))[-train]^2)
set.seed(2)
train=sample(392,196)
lm.fit=lm(mpg~horsepower,data=Auto,subset = train) 
attach(Auto)
mean((mpg-predict(lm.fit,Auto))[-train]^2)
lm.fit2=lm(mpg~poly(horsepower,2),data=Auto,subset = train)
mean((mpg-predict(lm.fit2,Auto))[-train]^2)
lm.fit3=lm(mpg~poly(horsepower,3),data=Auto,subset = train)
mean((mpg-predict(lm.fit3,Auto))[-train]^2)
#b)
##LOOCV
library(boot)
glm.fit=glm(mpg~horsepower,data=Auto)
cv.err=cv.glm(Auto,glm.fit)
cv.err$delta
cv.error=rep(0,10)
for(i in 1:10){
  glm.fit=glm(mpg~poly(horsepower,i),data=Auto)
  cv.error[i]=cv.glm(Auto,glm.fit)$delta[1]
}
cv.error
#c)
#k-fold cross validation
set.seed(17)
cv.error.10=rep(0,10)
for(i in 1:10){
  glm.fit=glm(mpg~poly(horsepower,i),data=Auto)
  cv.error.10[i]=cv.glm(Auto,glm.fit,K=10)$delta[1]
}
cv.error.10
#k=5
cv.error.5=rep(0,10)
for(i in 1:10){
  glm.fit=glm(mpg~poly(horsepower,i),data=Auto)
  cv.error.5[i]=cv.glm(Auto,glm.fit,K=5)$delta[1]
}
cv.error.5





```

#Q.2)
```{r}
library(ISLR2)
data(Portfolio)
library(boot)
#bootstrap
set.seed(10)
alpha.fn=function(data,index){
  X=data$X[index]
  Y=data$Y[index]
  (var(Y)-cov(X,Y))/(var(X)+var(Y)-2*cov(X,Y))
}
alpha.fn(Portfolio,1:100)
set.seed(10)
alpha.fn(Portfolio,sample(100,100,replace = T))
boot(Portfolio,alpha.fn,R=1000)
plot(boot(Portfolio,alpha.fn,R=1000))

```

# Q.3
```{r}
data("Default")
#View(Default)
df=Default
attach(Default)
set.seed(123)
#a)
lr.fit2=glm(default~income+balance,data=df,family = binomial)
summary(lr.fit2)$coefficients
summary(lr.fit2)$coefficients[2:3,2]
```
```{r}
#b) and c)
boot.fn=function(data,index){
  default=data$default[index]
  income=data$income[index]
  balance=data$balance[index]
  lr.fit2=glm(default~income+balance,family = binomial)
  return(summary(lr.fit2)$coefficients[2:3,2])
}
#b)
boot.fn(df,1:length(df$default))
#c
# using boo()with R=100
library(boot)
boot(df,boot.fn,100)

#orr

boot.fn=function(data,index){
  default=data$default[index]
  income=data$income[index]
  balance=data$balance[index]
  lr.fit2=glm(default~income+balance,family = binomial)
  return(summary(lr.fit2)$coefficients[2:3,1])
}

```

#Q4
```{r}
attach(Boston)
# a) mean of medv
mu_hat=mean(Boston$medv)
# b) sandard deviation of mean
n_=length(Boston$medv)
s=sqrt(sum((Boston$medv-mu_hat)^2)/(n_-1))# sigma _hat sd(Boston$medv)
#s=sd(Boston$medv)
#sandard error of mean
se=s/sqrt(n_)
se

# c) sandard error using bootstrapping
boot.fn2=function(data,index){
  X=data$medv[index]
  mu2=mean(X)
 return(mu2) 
}
set.seed(1)
boot(Boston,boot.fn2,1000)

# d) 95% CI for population mean of medv (without boot)
mu_hat-1.96*se #lower bound
mu_hat+1.96*se #upper bound
cbind(mu_hat-1.96*se,mu_hat+1.96*se )
t.test(Boston$medv)

# 95% CI for population mean of medv (with boot)
mu_hat-1.96*0.4106622 #lower bound
mu_hat+1.96*0.4106622 #upper bound

#median value of medv
median.medv=median(Boston$medv)

# f) bootstrapping estimate of the sandard error of the median value
boot.fn3=function(data,index){
  X=data$medv[index]
  Y=median(X)
 return(Y) 
}
boot(Boston,boot.fn3,1000)

# 95% CI for population median of medv (with boot) using median fun.
21.2-1.96*0.3770241
21.2+1.96*0.3770241

# g) tenth percentile value of medv
tenth.percentile=quantile(Boston$medv,0.1)

# h) bootstrapping estimate of the sandard error of the tenth percentile value
boot.fn4=function(data,index){
  X=data$medv[index]
  Y=quantile(X,0.1)
 return(Y) 
}
boot(Boston,boot.fn4,1000)

# 95% CI for population mean of medv (with boot) using quantil fun.
12.75-1.96*0.5059657
12.75+1.96*0.5059657
```

# Q.5)
```{r}
#a) Fit a simple linear regression model
data(cars)
lm.fit = lm(dist ~ speed, data = cars) #distance=β0+β1×speed+ϵ
summary(lm.fit)

#b) Prediction interval (standard method)
new = data.frame(speed = 20)
predict(lm.fit, newdata = new, interval = "prediction", level = 0.95)

#c) Non-parametric bootstrap prediction interval
library(boot)

boot.fn = function(data, index, x0 = 20) {
  fit = lm(dist ~ speed, data = data, subset = index)
  predict(fit, newdata = data.frame(speed = x0))
}

set.seed(1)
boot.pred = boot(cars, statistic = boot.fn, R = 1000)

# Bootstrap 95% prediction interval
quantile(boot.pred$t, c(0.025, 0.975))

#d) Parametric bootstrap prediction interval
set.seed(1)
n = nrow(cars)
B = 1000
y.pred = numeric(B)

#for (b in 1:B) {
  #y.sim = fitted(lm.fit) + rnorm(n, mean = 0, sd = summary(lm.fit)$sigma)
  #fit.sim = lm(y.sim ~ cars$speed)
  #y.pred[b] = predict(fit.sim, newdata = data.frame(speed = 20))}


quantile(y.pred, c(0.025, 0.975))
#o\p
#2.5%    97.5% 
#54.29951 67.42220 





```




